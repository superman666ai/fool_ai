三．模型评估方法


接下来我们介绍几种常见的模型评估的方法：留出法、交叉验证法、留一法（交叉验证法的一个特例）以及自助法。

1. 留出法

“留出法”（hold-out）是一种较为简单的方法，它直接将数据集划分为训练集和验证集，集合和集合是互斥的


需要注意的是，为了确保“训练集”和“验证集”中数据分布的一致性，我们需要使用“分层采样”的方式划分数据集。举个简单的例子，假设我们的数据集中有100个样本，其中有50个正例和50个负例。我们假设训练集和验证集的样本数比例为，即训练集有80个样本，验证集有20个样本。若使用“分层采样”，则训练集中应该有40个正例和40个负例，而验证集中应该有10个正例和10个负例。


由于数据的划分具有随机性，通过一次划分数据集训练后得到的模型，在“验证集”上的表现不一定能体现出模型真正的效果。因此我们一般会多次划分数据集并训练模型，并取多次实验结果的平均值作为最终模型评估的结果。


“留出法”还存在一个问题，那就是“训练集”和“验证集”的比例该如何确定。这个问题在数据样本足够多的时候可以不用考虑，但在数据样本不是特别多的时候就会造成一定困扰，一般的做法是将的数据作为“验证集”。

2. 交叉验证法

“交叉验证法”（cross validation）将数据集划分为个大小相同，但互斥的子集，即。为了确保数据分布的一致性，这里我们同样使用“分层采样”的方式划分数据集。


对于划分得到的个数据集，我们每次使用其中的一个作为“验证集”，剩下的个作为“训练集”，将得到的个结果取平均值，作为最终模型评估的结果，我们称这种方法为“k折交叉验证”。和“留出法”一样，为了排除数据集划分的影响，我们对数据集进行次划分，每次划分得到个子集，然后进行次“k折交叉验证”，并取这次“k折交叉验证”结果的平均值作为最终的结果。我们称这种方法为“次k折交叉验证”，常见的有“5次10折交叉验证”或“10次10折交叉验证”。



“交叉验证法”有一种特殊地情况，假设我们的数据集大小为，若使得的值等于，则把这种情况称为“留一法”，因为这时我们的“验证集”中只有一个样本。“留一法”的优点是不存在数据集划分所产生的影响，但是当数据集较大时，对于样本数量为的数据集，使用“留一法”需要训练个模型，这会需要很大的计算开销。

3. 自助法

“自助法”是一种基于自助采样的方法，通过采样从原始数据集中产生一个训练集。


